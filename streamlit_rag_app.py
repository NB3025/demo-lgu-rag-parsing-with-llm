#!/usr/bin/env python3
"""
Streamlit RAG Ï±ÑÌåÖ Ïï±
ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâÍ≥º Claude 3.5 Sonnet Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµÏùÑ Ï†úÍ≥µÌïòÎäî Ïõπ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
"""

import streamlit as st
import json
import boto3
from pathlib import Path
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
from typing import List, Dict, Any, Generator
import time
import re

# ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï
st.set_page_config(
    page_title="üöó ÏûêÎèôÏ∞® Îß§Îâ¥Ïñº AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

class StreamlitRAGChatbot:
    def __init__(self, config_file='opensearch_config.json'):
        """Streamlit RAG Ï±ÑÌåÖÎ¥á Ï¥àÍ∏∞Ìôî"""
        self.config = self.load_config(config_file)
        if not self.config:
            st.error("ÏÑ§Ï†ï ÌååÏùºÏùÑ Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§")
            st.stop()
        
        # AWS ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî
        self.region = self.config['region']
        self.bedrock_client = boto3.client('bedrock-runtime', region_name=self.region)
        self.s3_client = boto3.client('s3', region_name=self.region)  # S3 ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï∂îÍ∞Ä
        self.opensearch_client = self.setup_opensearch_client()
        
        # Claude 3.5 Sonnet Î™®Îç∏ ID
        self.claude_model_id = "anthropic.claude-3-5-sonnet-20241022-v2:0"
        
        # ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏
        self.system_prompt = """ÎãπÏã†ÏùÄ ÏûêÎèôÏ∞® Îß§Îâ¥Ïñº Ï†ÑÎ¨∏ AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. 
ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎåÄÌï¥ ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâÏúºÎ°ú Ï∞æÏùÄ Î¨∏ÏÑú ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú Ï†ïÌôïÌïòÍ≥† ÎèÑÏõÄÏù¥ ÎêòÎäî ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÏÑ∏Ïöî.

ÎãµÎ≥Ä Í∞ÄÏù¥ÎìúÎùºÏù∏:
1. Ï†úÍ≥µÎêú Î¨∏ÏÑú ÎÇ¥Ïö©ÎßåÏùÑ Î∞îÌÉïÏúºÎ°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî
2. Î¨∏ÏÑúÏóê ÏóÜÎäî ÎÇ¥Ïö©ÏùÄ Ï∂îÏ∏°ÌïòÏßÄ ÎßàÏÑ∏Ïöî
3. Íµ¨Ï≤¥Ï†ÅÏù∏ Ï†àÏ∞®ÎÇò ÏàòÏπòÍ∞Ä ÏûàÎã§Î©¥ Ï†ïÌôïÌûà Ïù∏Ïö©ÌïòÏÑ∏Ïöî
4. ÎãµÎ≥Ä ÎßàÏßÄÎßâÏóê Ï∞∏Ï°∞Ìïú ÌéòÏù¥ÏßÄ Ï†ïÎ≥¥Î•º Ìè¨Ìï®ÌïòÏÑ∏Ïöî
5. ÌïúÍµ≠Ïñ¥Î°ú ÏπúÍ∑ºÌïòÍ≥† Ïù¥Ìï¥ÌïòÍ∏∞ ÏâΩÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî

ÎãµÎ≥Ä ÌòïÏãù:
- ÏßàÎ¨∏Ïóê ÎåÄÌïú ÏßÅÏ†ëÏ†ÅÏù∏ ÎãµÎ≥Ä
- Íµ¨Ï≤¥Ï†ÅÏù∏ ÏÑ§Î™ÖÏù¥ÎÇò Ï†àÏ∞® (Îã®Í≥ÑÎ≥ÑÎ°ú ÏÑ§Î™Ö)
- Ï£ºÏùòÏÇ¨Ìï≠Ïù¥ÎÇò Ï∂îÍ∞Ä Ï†ïÎ≥¥
- Ï∞∏Ï°∞: ÌéòÏù¥ÏßÄ X"""
    
    @st.cache_data
    def load_config(_self, config_file: str) -> Dict:
        """ÏÑ§Ï†ï ÌååÏùº Î°úÎìú (Ï∫êÏãúÎê®)"""
        try:
            config_path = Path(config_file)
            if not config_path.exists():
                return None
            
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"ÏÑ§Ï†ï ÌååÏùº Î°úÎìú Ïò§Î•ò: {e}")
            return None
    
    def setup_opensearch_client(self):
        """OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÑ§Ï†ï"""
        session = boto3.Session()
        credentials = session.get_credentials()
        
        auth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            self.region,
            'aoss',
            session_token=credentials.token
        )
        
        client = OpenSearch(
            hosts=[{
                'host': self.config['endpoint'].replace('https://', ''),
                'port': 443
            }],
            http_auth=auth,
            use_ssl=True,
            verify_certs=True,
            connection_class=RequestsHttpConnection,
            pool_maxsize=20
        )
        
        return client
    
    def generate_presigned_url(self, s3_uri: str, expiration: int = 3600) -> str:
        """S3 URIÎ•º presigned URLÎ°ú Î≥ÄÌôò"""
        try:
            # S3 URI ÌååÏã± (s3://bucket/key ÌòïÌÉú)
            if not s3_uri.startswith('s3://'):
                return None
            
            # s3:// Ï†úÍ±∞ÌïòÍ≥† bucketÍ≥º key Î∂ÑÎ¶¨
            s3_path = s3_uri[5:]  # s3:// Ï†úÍ±∞
            bucket_name, key = s3_path.split('/', 1)
            
            # presigned URL ÏÉùÏÑ±
            presigned_url = self.s3_client.generate_presigned_url(
                'get_object',
                Params={'Bucket': bucket_name, 'Key': key},
                ExpiresIn=expiration
            )
            
            return presigned_url
            
        except Exception as e:
            st.error(f"Presigned URL ÏÉùÏÑ± Ïò§Î•ò: {e}")
            return None
    
    def get_embedding(self, text: str) -> List[float]:
        """ÌÖçÏä§Ìä∏Î•º ÏûÑÎ≤†Îî©ÏúºÎ°ú Î≥ÄÌôò"""
        try:
            response = self.bedrock_client.invoke_model(
                modelId="amazon.titan-embed-text-v2:0",
                body=json.dumps({
                    "inputText": text,
                    "dimensions": 1024,
                    "normalize": True
                })
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['embedding']
            
        except Exception as e:
            st.error(f"ÏûÑÎ≤†Îî© ÏÉùÏÑ± Ïò§Î•ò: {e}")
            return None
    
    def search_documents(self, query: str, k: int = 5) -> List[Dict]:
        """Î≤°ÌÑ∞ + Î†âÏãúÏª¨ Í≤ÄÏÉâÏùÑ Î≥ÑÎèÑÎ°ú ÏàòÌñâÌïòÏó¨ Í≤∞Ìï©"""
        all_results = []
        
        # 1. Î≤°ÌÑ∞ Í≤ÄÏÉâ ÏàòÌñâ
        vector_results = self.vector_search(query, k)
        
        # 2. Î†âÏãúÏª¨ Í≤ÄÏÉâ ÏàòÌñâ
        lexical_results = self.lexical_search_only(query, k)
        
        # 3. Í≤∞Í≥º Í≤∞Ìï© Î∞è Ï§ëÎ≥µ Ï†úÍ±∞
        seen_ids = set()
        
        # Î≤°ÌÑ∞ Í≤ÄÏÉâ Í≤∞Í≥º Ï∂îÍ∞Ä (ÎÜíÏùÄ Í∞ÄÏ§ëÏπò)
        for result in vector_results:
            result_id = f"{result['source_uri']}_{result['page_number']}"
            if result_id not in seen_ids:
                result['search_type'] = 'vector'
                result['combined_score'] = result['score'] * 1.2  # Î≤°ÌÑ∞ Í≤ÄÏÉâÏóê Í∞ÄÏ§ëÏπò
                all_results.append(result)
                seen_ids.add(result_id)
        
        # Î†âÏãúÏª¨ Í≤ÄÏÉâ Í≤∞Í≥º Ï∂îÍ∞Ä
        for result in lexical_results:
            result_id = f"{result['source_uri']}_{result['page_number']}"
            if result_id not in seen_ids:
                result['search_type'] = 'lexical'
                result['combined_score'] = result['score']
                all_results.append(result)
                seen_ids.add(result_id)
            else:
                # Ïù¥ÎØ∏ ÏûàÎäî Í≤∞Í≥ºÎùºÎ©¥ Ï†êÏàò Ï°∞Ìï©
                for existing in all_results:
                    existing_id = f"{existing['source_uri']}_{existing['page_number']}"
                    if existing_id == result_id:
                        existing['combined_score'] = (existing['combined_score'] + result['score']) / 2
                        existing['search_type'] = 'hybrid'
                        break
        
        # Í≤∞Ìï©Îêú Ï†êÏàòÎ°ú Ï†ïÎ†¨
        all_results.sort(key=lambda x: x['combined_score'], reverse=True)
        
        return all_results[:k]
    
    def vector_search(self, query: str, k: int = 5) -> List[Dict]:
        """Î≤°ÌÑ∞ Í≤ÄÏÉâÎßå ÏàòÌñâ"""
        query_embedding = self.get_embedding(query)
        if not query_embedding:
            return []
        
        search_body = {
            "size": k,
            "query": {
                "knn": {
                    "bedrock-knowledge-base-default-vector": {
                        "vector": query_embedding,
                        "k": k
                    }
                }
            },
            "_source": {
                "excludes": ["bedrock-knowledge-base-default-vector"]
            }
        }
        
        try:
            response = self.opensearch_client.search(
                index=self.config['index_name'],
                body=search_body
            )
            
            return self.format_search_results(response)
            
        except Exception as e:
            st.error(f"Î≤°ÌÑ∞ Í≤ÄÏÉâ Ïò§Î•ò: {e}")
            return []
    
    def lexical_search_only(self, query: str, k: int = 5) -> List[Dict]:
        """Î†âÏãúÏª¨ Í≤ÄÏÉâÎßå ÏàòÌñâ"""
        search_body = {
            "size": k,
            "query": {
                "multi_match": {
                    "query": query,
                    "fields": [
                        "AMAZON_BEDROCK_TEXT^3",
                        "title_extracted^2",
                        "category"
                    ],
                    "type": "best_fields",
                    "fuzziness": "AUTO",
                    "analyzer": "nori"
                }
            },
            "_source": {
                "excludes": ["bedrock-knowledge-base-default-vector"]
            },
            "highlight": {
                "fields": {
                    "AMAZON_BEDROCK_TEXT": {
                        "fragment_size": 150,
                        "number_of_fragments": 2
                    }
                }
            }
        }
        
        try:
            response = self.opensearch_client.search(
                index=self.config['index_name'],
                body=search_body
            )
            
            return self.format_search_results(response)
            
        except Exception as e:
            st.error(f"Î†âÏãúÏª¨ Í≤ÄÏÉâ Ïò§Î•ò: {e}")
            return []
    
    def format_search_results(self, response: Dict) -> List[Dict]:
        """Í≤ÄÏÉâ Í≤∞Í≥º Ìè¨Îß∑ÌåÖ"""
        results = []
        hits = response.get('hits', {}).get('hits', [])
        
        for i, hit in enumerate(hits, 1):
            source = hit['_source']
            score = hit['_score']
            highlight = hit.get('highlight', {})
            
            result = {
                'rank': i,
                'score': score,
                'content': source.get('AMAZON_BEDROCK_TEXT', ''),
                'source_uri': source.get('x-amz-bedrock-kb-source-uri', ''),
                'page_number': source.get('x-amz-bedrock-kb-document-page-number', 'N/A'),
                'page_image_uri': source.get('page_image_uri', ''),
                'title': source.get('title_extracted', ''),
                'category': source.get('category', '')
            }
            
            # ÌïòÏù¥ÎùºÏù¥Ìä∏ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            if highlight:
                highlighted_text = highlight.get('AMAZON_BEDROCK_TEXT', [])
                if highlighted_text:
                    result['highlighted_snippets'] = highlighted_text
            
            results.append(result)
        
        return results
    
    def build_context(self, search_results: List[Dict]) -> str:
        """Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±"""
        if not search_results:
            return "Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."
        
        context_parts = []
        context_parts.append("=== Í¥ÄÎ†® Î¨∏ÏÑú ÎÇ¥Ïö© ===\n")
        
        for result in search_results:
            page_num = result['page_number']
            page_display = f"ÌéòÏù¥ÏßÄ {page_num + 1}" if isinstance(page_num, int) else f"ÌéòÏù¥ÏßÄ {page_num}"
            
            context_parts.append(f"[{page_display}]")
            context_parts.append(result['content'])
            context_parts.append("---")
        
        return "\n".join(context_parts)
    
    def stream_claude_response(self, user_question: str, context: str) -> Generator[str, None, None]:
        """Claude 3.5 Sonnet Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµ ÏÉùÏÑ±"""
        try:
            messages = [
                {
                    "role": "user",
                    "content": f"""ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: {user_question}

{context}

ÏúÑ Î¨∏ÏÑú ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî."""
                }
            ]
            
            # Ïä§Ìä∏Î¶¨Î∞ç ÏöîÏ≤≠
            response = self.bedrock_client.invoke_model_with_response_stream(
                modelId=self.claude_model_id,
                body=json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 2000,
                    "system": self.system_prompt,
                    "messages": messages,
                    "temperature": 0.1
                })
            )
            
            # Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµ Ï≤òÎ¶¨
            for event in response['body']:
                chunk = json.loads(event['chunk']['bytes'])
                
                if chunk['type'] == 'content_block_delta':
                    if 'delta' in chunk and 'text' in chunk['delta']:
                        yield chunk['delta']['text']
                        
        except Exception as e:
            yield f"‚ùå ÎãµÎ≥Ä ÏÉùÏÑ± Ïò§Î•ò: {e}"

# Streamlit Ïï± Ï¥àÍ∏∞Ìôî
@st.cache_resource
def init_chatbot():
    """Ï±ÑÌåÖÎ¥á Ï¥àÍ∏∞Ìôî (Ï∫êÏãúÎê®)"""
    return StreamlitRAGChatbot()

def display_search_results(search_results: List[Dict], chatbot):
    """Í≤ÄÏÉâ Í≤∞Í≥º ÌëúÏãú (Ïù¥ÎØ∏ÏßÄ Ìè¨Ìï®)"""
    if not search_results:
        st.warning("Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.")
        return
    
    st.subheader(f"üîç Í≤ÄÏÉâ Í≤∞Í≥º ({len(search_results)}Í∞ú)")
    
    for i, result in enumerate(search_results):
        # Í≤ÄÏÉâ ÌÉÄÏûÖ ÌëúÏãú
        search_type_emoji = {
            'vector': 'üß†',
            'lexical': 'üîç', 
            'hybrid': '‚ö°'
        }
        search_type = result.get('search_type', 'unknown')
        type_emoji = search_type_emoji.get(search_type, '‚ùì')
        
        with st.expander(f"{type_emoji} {result.get('title', 'Ï†úÎ™© ÏóÜÏùå')} - ÌéòÏù¥ÏßÄ {result['page_number'] + 1 if isinstance(result['page_number'], int) else result['page_number']} (Ï†êÏàò: {result.get('combined_score', result['score']):.3f})"):
            
            # Í∏∞Î≥∏ Ï†ïÎ≥¥
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Í≤ÄÏÉâ ÌÉÄÏûÖ Î∞∞ÏßÄ
                if search_type != 'unknown':
                    st.badge(f"{search_type.upper()} Í≤ÄÏÉâ")
                
                if result.get('category'):
                    st.badge(result['category'])
                
                # ÌïòÏù¥ÎùºÏù¥Ìä∏Îêú ÌÖçÏä§Ìä∏ ÌëúÏãú
                if result.get('highlighted_snippets'):
                    st.markdown("**üîç Îß§Ïπ≠ Íµ¨Í∞Ñ:**")
                    for snippet in result['highlighted_snippets'][:2]:
                        # HTML ÌÉúÍ∑∏Î•º ÎßàÌÅ¨Îã§Ïö¥ÏúºÎ°ú Î≥ÄÌôò
                        clean_snippet = snippet.replace('<em>', '**').replace('</em>', '**')
                        st.markdown(f"‚Ä¢ {clean_snippet}")
                else:
                    # ÏùºÎ∞ò ÎØ∏Î¶¨Î≥¥Í∏∞
                    preview = result['content'][:200] + "..." if len(result['content']) > 200 else result['content']
                    st.markdown(f"**üìù ÎÇ¥Ïö© ÎØ∏Î¶¨Î≥¥Í∏∞:**\n{preview}")
            
            with col2:
                # Ïù¥ÎØ∏ÏßÄ ÌëúÏãú
                if result.get('page_image_uri'):
                    st.markdown("**üñºÔ∏è ÌéòÏù¥ÏßÄ Ïù¥ÎØ∏ÏßÄ:**")
                    try:
                        # S3 presigned URL ÏÉùÏÑ±
                        presigned_url = chatbot.generate_presigned_url(result['page_image_uri'])
                        
                        if presigned_url:
                            # Ïù¥ÎØ∏ÏßÄ ÏßÅÏ†ë ÌëúÏãú
                            st.image(presigned_url, caption=f"ÌéòÏù¥ÏßÄ {result['page_number'] + 1 if isinstance(result['page_number'], int) else result['page_number']}", width=200)
                        else:
                            st.caption("Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§")
                            st.code(result['page_image_uri'])
                    except Exception as e:
                        st.caption(f"Ïù¥ÎØ∏ÏßÄ Î°úÎî© Ïò§Î•ò: {e}")
                        st.code(result['page_image_uri'])

def main():
    """Î©îÏù∏ Ïï±"""
    # Ìó§Îçî
    st.title("üöó ÏûêÎèôÏ∞® Îß§Îâ¥Ïñº AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏")
    st.markdown("**Î≤°ÌÑ∞ + Î†âÏãúÏª¨ Í≤ÄÏÉâ Í≤∞Ìï© + Claude 3.5 Sonnet Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµ**")
    
    # ÏÇ¨Ïù¥ÎìúÎ∞î
    with st.sidebar:
        st.header("‚öôÔ∏è ÏÑ§Ï†ï")
        
        # Í≤ÄÏÉâ ÏÑ§Ï†ï
        max_results = st.slider("Í≤ÄÏÉâ Í≤∞Í≥º Ïàò", 1, 10, 5)
        show_search_details = st.checkbox("Í≤ÄÏÉâ Í≤∞Í≥º ÏÉÅÏÑ∏ Î≥¥Í∏∞", True)
        
        st.markdown("---")
        st.markdown("### üìä ÏãúÏä§ÌÖú Ï†ïÎ≥¥")
        
        # Ï±ÑÌåÖÎ¥á Ï¥àÍ∏∞Ìôî
        try:
            chatbot = init_chatbot()
            st.success("‚úÖ ÏãúÏä§ÌÖú Ï§ÄÎπÑ ÏôÑÎ£å")
            st.info(f"üåç Î¶¨Ï†Ñ: {chatbot.region}")
            st.info(f"üìÑ Ïù∏Îç±Ïä§: {chatbot.config['index_name']}")
        except Exception as e:
            st.error(f"‚ùå ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            st.stop()
    
    # Ï±ÑÌåÖ ÌûàÏä§ÌÜ†Î¶¨ Ï¥àÍ∏∞Ìôî
    if "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.search_results = []
    
    # Ï±ÑÌåÖ ÌûàÏä§ÌÜ†Î¶¨ ÌëúÏãú
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏûàÎäî Í≤ΩÏö∞ ÌëúÏãú
            if message["role"] == "assistant" and "search_results" in message:
                if show_search_details and message["search_results"]:
                    display_search_results(message["search_results"], chatbot)
    
    # ÏÇ¨Ïö©Ïûê ÏûÖÎ†•
    if prompt := st.chat_input("ÏûêÎèôÏ∞® Îß§Îâ¥ÏñºÏóê ÎåÄÌï¥ Î¨¥ÏóáÏù¥Îì† Î¨ºÏñ¥Î≥¥ÏÑ∏Ïöî..."):
        # ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ Ï∂îÍ∞Ä
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ÏùëÎãµ ÏÉùÏÑ±
        with st.chat_message("assistant"):
            # Í≤ÄÏÉâ ÏàòÌñâ
            with st.spinner("üîç Í¥ÄÎ†® Î¨∏ÏÑú Í≤ÄÏÉâ Ï§ë..."):
                search_results = chatbot.search_documents(prompt, max_results)
            
            if not search_results:
                st.error("Í¥ÄÎ†®Îêú Î¨∏ÏÑúÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Îã§Î•∏ ÏßàÎ¨∏ÏùÑ ÏãúÎèÑÌï¥Î≥¥ÏÑ∏Ïöî.")
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "Í¥ÄÎ†®Îêú Î¨∏ÏÑúÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Îã§Î•∏ ÏßàÎ¨∏ÏùÑ ÏãúÎèÑÌï¥Î≥¥ÏÑ∏Ïöî.",
                    "search_results": []
                })
            else:
                # Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
                context = chatbot.build_context(search_results)
                
                # Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµ ÌëúÏãú
                response_placeholder = st.empty()
                full_response = ""
                
                with st.spinner("ü§ñ Claude 3.5 SonnetÏù¥ ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÍ≥† ÏûàÏäµÎãàÎã§..."):
                    for chunk in chatbot.stream_claude_response(prompt, context):
                        full_response += chunk
                        response_placeholder.markdown(full_response + "‚ñå")
                
                # ÏµúÏ¢Ö ÏùëÎãµ ÌëúÏãú
                response_placeholder.markdown(full_response)
                
                # Í≤ÄÏÉâ Í≤∞Í≥º ÌëúÏãú
                if show_search_details:
                    display_search_results(search_results, chatbot)
                
                # ÏÑ∏ÏÖòÏóê Ï†ÄÏû•
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "search_results": search_results
                })
    
    # ÌïòÎã® Ï†ïÎ≥¥
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üí¨ ÎåÄÌôî Ïàò", len([m for m in st.session_state.messages if m["role"] == "user"]))
    
    with col2:
        if st.session_state.messages:
            last_search = next((m["search_results"] for m in reversed(st.session_state.messages) if "search_results" in m), [])
            st.metric("üîç ÎßàÏßÄÎßâ Í≤ÄÏÉâ Í≤∞Í≥º", len(last_search))
    
    with col3:
        if st.button("üóëÔ∏è ÎåÄÌôî Ï¥àÍ∏∞Ìôî"):
            st.session_state.messages = []
            st.session_state.search_results = []
            st.rerun()

if __name__ == "__main__":
    main()
