#!/usr/bin/env python3
"""
Streamlit RAG ì±„íŒ… ì•±
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê³¼ Claude 3.5 Sonnet ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
import json
import boto3
from pathlib import Path
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
from typing import List, Dict, Any, Generator
import time
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸš— ìë™ì°¨ ë§¤ë‰´ì–¼ AI ì–´ì‹œìŠ¤í„´íŠ¸",
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="expanded"
)

class StreamlitRAGChatbot:
    def __init__(self, config_file='opensearch_config.json'):
        """Streamlit RAG ì±„íŒ…ë´‡ ì´ˆê¸°í™”"""
        self.config = self.load_config(config_file)
        if not self.config:
            st.error("ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            st.stop()
        
        # AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.region = self.config['region']
        self.bedrock_client = boto3.client('bedrock-runtime', region_name=self.region)
        self.s3_client = boto3.client('s3', region_name=self.region)  # S3 í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€
        self.opensearch_client = self.setup_opensearch_client()
        
        # Claude 3.5 Sonnet ëª¨ë¸ ID
        self.claude_model_id = "anthropic.claude-3-5-sonnet-20241022-v2:0"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = """ë‹¹ì‹ ì€ ìë™ì°¨ ë§¤ë‰´ì–¼ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. êµ¬ì²´ì ì¸ ì ˆì°¨ë‚˜ ìˆ˜ì¹˜ê°€ ìˆë‹¤ë©´ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”
4. ë‹µë³€ ë§ˆì§€ë§‰ì— ì°¸ì¡°í•œ í˜ì´ì§€ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
5. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€ í˜•ì‹:
- ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
- êµ¬ì²´ì ì¸ ì„¤ëª…ì´ë‚˜ ì ˆì°¨ (ë‹¨ê³„ë³„ë¡œ ì„¤ëª…)
- ì£¼ì˜ì‚¬í•­ì´ë‚˜ ì¶”ê°€ ì •ë³´
- ì°¸ì¡°: í˜ì´ì§€ X"""
    
    @st.cache_data
    def load_config(_self, config_file: str) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ (ìºì‹œë¨)"""
        try:
            config_path = Path(config_file)
            if not config_path.exists():
                return None
            
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    def setup_opensearch_client(self):
        """OpenSearch í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        session = boto3.Session()
        credentials = session.get_credentials()
        
        auth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            self.region,
            'aoss',
            session_token=credentials.token
        )
        
        client = OpenSearch(
            hosts=[{
                'host': self.config['endpoint'].replace('https://', ''),
                'port': 443
            }],
            http_auth=auth,
            use_ssl=True,
            verify_certs=True,
            connection_class=RequestsHttpConnection,
            pool_maxsize=20
        )
        
        return client
    
    def generate_presigned_url(self, s3_uri: str, expiration: int = 3600) -> str:
        """S3 URIë¥¼ presigned URLë¡œ ë³€í™˜"""
        try:
            # S3 URI íŒŒì‹± (s3://bucket/key í˜•íƒœ)
            if not s3_uri.startswith('s3://'):
                return None
            
            # s3:// ì œê±°í•˜ê³  bucketê³¼ key ë¶„ë¦¬
            s3_path = s3_uri[5:]  # s3:// ì œê±°
            bucket_name, key = s3_path.split('/', 1)
            
            # presigned URL ìƒì„±
            presigned_url = self.s3_client.generate_presigned_url(
                'get_object',
                Params={'Bucket': bucket_name, 'Key': key},
                ExpiresIn=expiration
            )
            
            return presigned_url
            
        except Exception as e:
            st.error(f"Presigned URL ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            response = self.bedrock_client.invoke_model(
                modelId="amazon.titan-embed-text-v2:0",
                body=json.dumps({
                    "inputText": text,
                    "dimensions": 1024,
                    "normalize": True
                })
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['embedding']
            
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def search_documents(self, query: str, k: int = 5) -> List[Dict]:
        """ë²¡í„° + ë ‰ì‹œì»¬ ê²€ìƒ‰ì„ ë³„ë„ë¡œ ìˆ˜í–‰í•˜ì—¬ ê²°í•©"""
        all_results = []
        
        # 1. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        vector_results = self.vector_search(query, k)
        
        # 2. ë ‰ì‹œì»¬ ê²€ìƒ‰ ìˆ˜í–‰
        lexical_results = self.lexical_search_only(query, k)
        
        # 3. ê²°ê³¼ ê²°í•© ë° ì¤‘ë³µ ì œê±°
        seen_ids = set()
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (ë†’ì€ ê°€ì¤‘ì¹˜)
        for result in vector_results:
            result_id = f"{result['source_uri']}_{result['page_number']}"
            if result_id not in seen_ids:
                result['search_type'] = 'vector'
                result['combined_score'] = result['score'] * 1.2  # ë²¡í„° ê²€ìƒ‰ì— ê°€ì¤‘ì¹˜
                all_results.append(result)
                seen_ids.add(result_id)
        
        # ë ‰ì‹œì»¬ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        for result in lexical_results:
            result_id = f"{result['source_uri']}_{result['page_number']}"
            if result_id not in seen_ids:
                result['search_type'] = 'lexical'
                result['combined_score'] = result['score']
                all_results.append(result)
                seen_ids.add(result_id)
            else:
                # ì´ë¯¸ ìˆëŠ” ê²°ê³¼ë¼ë©´ ì ìˆ˜ ì¡°í•©
                for existing in all_results:
                    existing_id = f"{existing['source_uri']}_{existing['page_number']}"
                    if existing_id == result_id:
                        existing['combined_score'] = (existing['combined_score'] + result['score']) / 2
                        existing['search_type'] = 'hybrid'
                        break
        
        # ê²°í•©ëœ ì ìˆ˜ë¡œ ì •ë ¬
        all_results.sort(key=lambda x: x['combined_score'], reverse=True)
        
        return all_results[:k]
    
    def vector_search(self, query: str, k: int = 5) -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ë§Œ ìˆ˜í–‰"""
        query_embedding = self.get_embedding(query)
        if not query_embedding:
            return []
        
        search_body = {
            "size": k,
            "query": {
                "knn": {
                    "bedrock-knowledge-base-default-vector": {
                        "vector": query_embedding,
                        "k": k
                    }
                }
            },
            "_source": {
                "excludes": ["bedrock-knowledge-base-default-vector"]
            }
        }
        
        try:
            response = self.opensearch_client.search(
                index=self.config['index_name'],
                body=search_body
            )
            
            return self.format_search_results(response)
            
        except Exception as e:
            st.error(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def lexical_search_only(self, query: str, k: int = 5) -> List[Dict]:
        """ë ‰ì‹œì»¬ ê²€ìƒ‰ë§Œ ìˆ˜í–‰"""
        search_body = {
            "size": k,
            "query": {
                "multi_match": {
                    "query": query,
                    "fields": [
                        "AMAZON_BEDROCK_TEXT^3",
                        "title_extracted^2",
                        "category"
                    ],
                    "type": "best_fields",
                    "fuzziness": "AUTO",
                    "analyzer": "nori"
                }
            },
            "_source": {
                "excludes": ["bedrock-knowledge-base-default-vector"]
            },
            "highlight": {
                "fields": {
                    "AMAZON_BEDROCK_TEXT": {
                        "fragment_size": 150,
                        "number_of_fragments": 2
                    }
                }
            }
        }
        
        try:
            response = self.opensearch_client.search(
                index=self.config['index_name'],
                body=search_body
            )
            
            return self.format_search_results(response)
            
        except Exception as e:
            st.error(f"ë ‰ì‹œì»¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def format_search_results(self, response: Dict) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        results = []
        hits = response.get('hits', {}).get('hits', [])
        
        for i, hit in enumerate(hits, 1):
            source = hit['_source']
            score = hit['_score']
            highlight = hit.get('highlight', {})
            
            result = {
                'rank': i,
                'score': score,
                'content': source.get('AMAZON_BEDROCK_TEXT', ''),
                'source_uri': source.get('x-amz-bedrock-kb-source-uri', ''),
                'page_number': source.get('x-amz-bedrock-kb-document-page-number', 'N/A'),
                'page_image_uri': source.get('page_image_uri', ''),
                'title': source.get('title_extracted', ''),
                'category': source.get('category', '')
            }
            
            # í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ì¶”ê°€
            if highlight:
                highlighted_text = highlight.get('AMAZON_BEDROCK_TEXT', [])
                if highlighted_text:
                    result['highlighted_snippets'] = highlighted_text
            
            results.append(result)
        
        return results
    
    def build_context(self, search_results: List[Dict]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not search_results:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        context_parts.append("=== ê´€ë ¨ ë¬¸ì„œ ë‚´ìš© ===\n")
        
        for result in search_results:
            page_num = result['page_number']
            page_display = f"í˜ì´ì§€ {page_num + 1}" if isinstance(page_num, int) else f"í˜ì´ì§€ {page_num}"
            
            context_parts.append(f"[{page_display}]")
            context_parts.append(result['content'])
            context_parts.append("---")
        
        return "\n".join(context_parts)
    
    def stream_claude_response(self, user_question: str, context: str) -> Generator[str, None, None]:
        """Claude 3.5 Sonnet ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        try:
            messages = [
                {
                    "role": "user",
                    "content": f"""ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

{context}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""
                }
            ]
            
            # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
            response = self.bedrock_client.invoke_model_with_response_stream(
                modelId=self.claude_model_id,
                body=json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 2000,
                    "system": self.system_prompt,
                    "messages": messages,
                    "temperature": 0.1
                })
            )
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            for event in response['body']:
                chunk = json.loads(event['chunk']['bytes'])
                
                if chunk['type'] == 'content_block_delta':
                    if 'delta' in chunk and 'text' in chunk['delta']:
                        yield chunk['delta']['text']
                        
        except Exception as e:
            yield f"âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}"

# Streamlit ì•± ì´ˆê¸°í™”
@st.cache_resource
def init_chatbot():
    """ì±„íŒ…ë´‡ ì´ˆê¸°í™” (ìºì‹œë¨)"""
    return StreamlitRAGChatbot()

def display_search_results(search_results: List[Dict], chatbot):
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ì´ë¯¸ì§€ í¬í•¨)"""
    if not search_results:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.subheader(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ({len(search_results)}ê°œ)")
    
    for i, result in enumerate(search_results):
        # ê²€ìƒ‰ íƒ€ì… í‘œì‹œ
        search_type_emoji = {
            'vector': 'ğŸ§ ',
            'lexical': 'ğŸ”', 
            'hybrid': 'âš¡'
        }
        search_type = result.get('search_type', 'unknown')
        type_emoji = search_type_emoji.get(search_type, 'â“')
        
        with st.expander(f"{type_emoji} {result.get('title', 'ì œëª© ì—†ìŒ')} - í˜ì´ì§€ {result['page_number'] + 1 if isinstance(result['page_number'], int) else result['page_number']} (ì ìˆ˜: {result.get('combined_score', result['score']):.3f})"):
            
            # ê¸°ë³¸ ì •ë³´
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ê²€ìƒ‰ íƒ€ì… ë°°ì§€
                if search_type != 'unknown':
                    st.badge(f"{search_type.upper()} ê²€ìƒ‰")
                
                if result.get('category'):
                    st.badge(result['category'])
                
                # í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸ í‘œì‹œ
                if result.get('highlighted_snippets'):
                    st.markdown("**ğŸ” ë§¤ì¹­ êµ¬ê°„:**")
                    for snippet in result['highlighted_snippets'][:2]:
                        # HTML íƒœê·¸ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
                        clean_snippet = snippet.replace('<em>', '**').replace('</em>', '**')
                        st.markdown(f"â€¢ {clean_snippet}")
                else:
                    # ì¼ë°˜ ë¯¸ë¦¬ë³´ê¸°
                    preview = result['content'][:200] + "..." if len(result['content']) > 200 else result['content']
                    st.markdown(f"**ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:**\n{preview}")
            
            with col2:
                # ì´ë¯¸ì§€ í‘œì‹œ
                if result.get('page_image_uri'):
                    st.markdown("**ğŸ–¼ï¸ í˜ì´ì§€ ì´ë¯¸ì§€:**")
                    try:
                        # S3 presigned URL ìƒì„±
                        presigned_url = chatbot.generate_presigned_url(result['page_image_uri'])
                        
                        if presigned_url:
                            # ì´ë¯¸ì§€ ì§ì ‘ í‘œì‹œ
                            st.image(presigned_url, caption=f"í˜ì´ì§€ {result['page_number'] + 1 if isinstance(result['page_number'], int) else result['page_number']}", width=200)
                        else:
                            st.caption("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                            st.code(result['page_image_uri'])
                    except Exception as e:
                        st.caption(f"ì´ë¯¸ì§€ ë¡œë”© ì˜¤ë¥˜: {e}")
                        st.code(result['page_image_uri'])

def main():
    """ë©”ì¸ ì•±"""
    # í—¤ë”
    st.title("ğŸš— ìë™ì°¨ ë§¤ë‰´ì–¼ AI ì–´ì‹œìŠ¤í„´íŠ¸")
    st.markdown("**ë²¡í„° + ë ‰ì‹œì»¬ ê²€ìƒ‰ ê²°í•© + Claude 3.5 Sonnet ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ**")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ê²€ìƒ‰ ì„¤ì •
        max_results = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 1, 10, 5)
        show_search_details = st.checkbox("ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë³´ê¸°", True)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
        
        # ì±„íŒ…ë´‡ ì´ˆê¸°í™”
        try:
            chatbot = init_chatbot()
            st.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
            st.info(f"ğŸŒ ë¦¬ì „: {chatbot.region}")
            st.info(f"ğŸ“„ ì¸ë±ìŠ¤: {chatbot.config['index_name']}")
        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.stop()
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.search_results = []
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
            if message["role"] == "assistant" and "search_results" in message:
                if show_search_details and message["search_results"]:
                    display_search_results(message["search_results"], chatbot)
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ìë™ì°¨ ë§¤ë‰´ì–¼ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            # ê²€ìƒ‰ ìˆ˜í–‰
            with st.spinner("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
                search_results = chatbot.search_documents(prompt, max_results)
            
            if not search_results:
                st.error("ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                    "search_results": []
                })
            else:
                # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                context = chatbot.build_context(search_results)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
                response_placeholder = st.empty()
                full_response = ""
                
                with st.spinner("ğŸ¤– Claude 3.5 Sonnetì´ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    for chunk in chatbot.stream_claude_response(prompt, context):
                        full_response += chunk
                        response_placeholder.markdown(full_response + "â–Œ")
                
                # ìµœì¢… ì‘ë‹µ í‘œì‹œ
                response_placeholder.markdown(full_response)
                
                # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                if show_search_details:
                    display_search_results(search_results, chatbot)
                
                # ì„¸ì…˜ì— ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "search_results": search_results
                })
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ’¬ ëŒ€í™” ìˆ˜", len([m for m in st.session_state.messages if m["role"] == "user"]))
    
    with col2:
        if st.session_state.messages:
            last_search = next((m["search_results"] for m in reversed(st.session_state.messages) if "search_results" in m), [])
            st.metric("ğŸ” ë§ˆì§€ë§‰ ê²€ìƒ‰ ê²°ê³¼", len(last_search))
    
    with col3:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.session_state.search_results = []
            st.rerun()

if __name__ == "__main__":
    main()
